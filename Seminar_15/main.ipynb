{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import string\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "with open('intents.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions = []\n",
    "answers =[]\n",
    "# Перебираем все интенты в списке\n",
    "for intent in data['intents']:\n",
    "    # Получаем список паттернов для данного интента и добавляем его к общему массиву\n",
    "    questions.extend(intent['patterns'])\n",
    "    answers.extend(intent['responses'])\n",
    "\n",
    "test_question = \"What is a database?\"\n",
    "\n",
    "questions.append(test_question)\n",
    "fitered_questions = []\n",
    "\n",
    "for text in questions:\n",
    "    doc = nlp(text)\n",
    "    fitered_questions.append([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "fitered_questions = [' '.join(text) for text in fitered_questions]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "questions_cv = cv.fit_transform(fitered_questions)\n",
    "\n",
    "questions_cv = pd.DataFrame(questions_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "questions_tfidf = tfidf.fit_transform(fitered_questions)\n",
    "questions_tfidf = pd.DataFrame(questions_tfidf.toarray(), columns=cv.get_feature_names_out())\n",
    "\n",
    "questions_cv = questions_cv.to_numpy()\n",
    "questions_tfidf = questions_tfidf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Подготовим данные\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    patterns.extend(intent['patterns'])\n",
    "    tags.extend([intent['tag']] * len(intent['patterns']))\n",
    "\n",
    "processed_patterns = [preprocess_text(pattern) for pattern in patterns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "bow_matrix = count_vectorizer.fit_transform(processed_patterns)\n",
    "bow_matrix = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "bow_matrix = bow_matrix.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_patterns)\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_matrix = tfidf_matrix.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A database management system (DBMS) is a software application that is used to create, manage, and manipulate databases. A database is a collection of data that is organized in a specific way, allowing for efficient retrieval and manipulation of the data. A DBMS provides a set of tools and interfaces that allow users to create, modify, and query the database, as well as to control access to the data and maintain the integrity and consistency of the data. DBMSs are widely used in a variety of applications, including financial systems, customer relationship management systems, and online shopping systems. They are an essential component of many business and organization systems, as they allow for the efficient storage and management of large amounts of data.\n"
     ]
    }
   ],
   "source": [
    "# Функция для поиска наиболее схожего вопроса\n",
    "def find_most_similar_question(user_input, matrix, vectorizer, similarity_metric):\n",
    "    processed_input = preprocess_text(user_input)\n",
    "    input_vector = vectorizer.transform([processed_input])\n",
    "\n",
    "    # Вычислим схожесть с использованием выбранной метрики\n",
    "    similarities = similarity_metric(matrix, input_vector)\n",
    "\n",
    "    # Найдем индекс наиболее схожего вопроса\n",
    "    most_similar_index = similarities.argmax()\n",
    "\n",
    "    return patterns[most_similar_index], tags[most_similar_index]\n",
    "\n",
    "# Пример использования с косинусным расстоянием\n",
    "user_input = \"What mean db?\"\n",
    "most_similar_pattern, tag = find_most_similar_question(user_input, bow_matrix, count_vectorizer, cosine_similarity)\n",
    "\n",
    "# Выведем ответ\n",
    "for intent in data['intents']:\n",
    "    if intent['tag'] == tag:\n",
    "        print(intent['responses'][0])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming is the process of creating computer software by writing instructions that can be executed by a computer. Different programming languages include Python, Java, C++, and JavaScript. Best practices in programming include writing clean and readable code, using version control, following coding standards, and testing and debugging thoroughly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "most_similar_pattern, tag = find_most_similar_question(user_input, tfidf_matrix, tfidf_vectorizer, cosine_similarity)\n",
    "\n",
    "# Выведем ответ\n",
    "for intent in data['intents']:\n",
    "    if intent['tag'] == tag:\n",
    "        print(intent['responses'][0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data abstraction is a technique used in programming to hide the implementation details of data types and only expose their essential properties and behaviors. It allows programmers to create abstract data types (ADTs) that define the interface and operations of a data type without revealing how it is implemented. This separation of interface from implementation allows for better code maintainability, flexibility, and modularity.\n",
      "Data abstraction is a technique used in programming to hide the implementation details of data types and only expose their essential properties and behaviors. It allows programmers to create abstract data types (ADTs) that define the interface and operations of a data type without revealing how it is implemented. This separation of interface from implementation allows for better code maintainability, flexibility, and modularity.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "#Поиск ближайшего ответа с помощью коэффициента сходства Рэнда (Rand Index)\n",
    "# Коэффициент сходства Рэнда измеряет сходство между двумя кластеризациями или разбиениями. \n",
    "# В контексте поиска ближайшего ответа, мы используем его для измерения сходства между двумя наборами ответов.\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "best_sim = []\n",
    "for i in range(len(questions_cv)-1):\n",
    "    best_sim.append(rand_score(questions_cv[i,:], questions_cv[-1,:]))\n",
    "print(answers[best_sim.index(max(best_sim))])\n",
    "\n",
    "best_sim = []\n",
    "for i in range(len(questions_tfidf)-1):\n",
    "    best_sim.append(rand_score(questions_tfidf[i,:], questions_tfidf[-1,:]))\n",
    "print(answers[best_sim.index(max(best_sim))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data abstraction is a technique used in programming to hide the implementation details of data types and only expose their essential properties and behaviors. It allows programmers to create abstract data types (ADTs) that define the interface and operations of a data type without revealing how it is implemented. This separation of interface from implementation allows for better code maintainability, flexibility, and modularity.\n",
      "Data abstraction is a technique used in programming to hide the implementation details of data types and only expose their essential properties and behaviors. It allows programmers to create abstract data types (ADTs) that define the interface and operations of a data type without revealing how it is implemented. This separation of interface from implementation allows for better code maintainability, flexibility, and modularity.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "# Поиск ближайшего ответа с помощью Жаккара (Jaccard Similarity)\n",
    "# Жаккардово сходство измеряет схожесть между двумя множествами и \n",
    "# выражается отношением размера их пересечения к размеру их объединения.\n",
    "\n",
    "best_sim = []\n",
    "for i in range(len(questions_cv)-1):\n",
    "    best_sim.append(1 - distance.jaccard(questions_cv[i, :], questions_cv[-1, :]))\n",
    "print(answers[best_sim.index(max(best_sim))])\n",
    "\n",
    "best_sim = []\n",
    "for i in range(len(questions_tfidf)-1):\n",
    "    best_sim.append(1 - distance.jaccard(questions_tfidf[i, :], questions_tfidf[-1, :]))\n",
    "print(answers[best_sim.index(max(best_sim))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data abstraction is a technique used in programming to hide the implementation details of data types and only expose their essential properties and behaviors. It allows programmers to create abstract data types (ADTs) that define the interface and operations of a data type without revealing how it is implemented. This separation of interface from implementation allows for better code maintainability, flexibility, and modularity.\n",
      "Data abstraction is a technique used in programming to hide the implementation details of data types and only expose their essential properties and behaviors. It allows programmers to create abstract data types (ADTs) that define the interface and operations of a data type without revealing how it is implemented. This separation of interface from implementation allows for better code maintainability, flexibility, and modularity.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "#Поиск ближайшего ответа с помощью корреляции\n",
    "# Корреляция измеряет степень линейной зависимости между двумя переменными. \n",
    "#  В данном случае, между векторами ответов и векторами запросов.\n",
    "best_sim = []\n",
    "for i in range(len(questions_cv)-1):\n",
    "    best_sim.append(pearsonr(questions_cv[i,:], questions_cv[-1,:]))\n",
    "print(answers[best_sim.index(max(best_sim))])\n",
    "\n",
    "best_sim = []\n",
    "for i in range(len(questions_tfidf)-1):\n",
    "    best_sim.append(pearsonr(questions_tfidf[i,:], questions_tfidf[-1,:]))\n",
    "print(answers[best_sim.index(max(best_sim))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
